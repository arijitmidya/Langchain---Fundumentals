{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96404339-5243-474a-91ea-c6bba0dcbd98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\ariji\\anaconda3\\lib\\site-packages (1.50.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from openai) (0.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "! pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "235dca07-788a-4ae3-8472-10fe3550096c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in c:\\users\\ariji\\anaconda3\\lib\\site-packages (0.3.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from langchain_community) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from langchain_community) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.1 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from langchain_community) (0.3.1)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from langchain_community) (0.3.6)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from langchain_community) (0.1.129)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from langchain_community) (1.24.4)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from langchain_community) (2.5.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from langchain_community) (8.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from langchain<0.4.0,>=0.3.1->langchain_community) (0.3.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from langchain<0.4.0,>=0.3.1->langchain_community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain_community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.6->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (3.10.7)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain_community) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.1->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.1->langchain_community) (2.23.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\ariji\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain_community"
   ]
  },
  {
   "attachments": {
    "59b6161e-da7a-407e-ad6d-71a409e539f5.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "0d300004-7ffc-410b-bd0c-beca9ee646ee",
   "metadata": {},
   "source": [
    "# Memory\n",
    "\n",
    " In several applications, however, we often require a series of questions or a structured conversation to achieve a more contextually coherent \n",
    "interaction with the language model. LangChain provides memory buffers to facilitate a conversational interface where the information exchanged between\n",
    "the user and the model can be stored. These memory buffers act as a context store, allowing the model to retain and utilize relevant information from \n",
    "previous messages in the ongoing conversation.\n",
    "\n",
    "Memory buffers are useful for scenarios such as dialogue systems, chatbots, virtual assistants, and interactive systems that involve multiturn \n",
    "interactions. This enables a more natural and intuitive communication with the language model that is contextually aware.\n",
    "\n",
    "A Memory for a chain can be visualized below : \n",
    "\n",
    "![image.png](attachment:59b6161e-da7a-407e-ad6d-71a409e539f5.png)\n",
    "\n",
    "Upon receiving a user query, a chain combined with conversations in the memory then passes to the model.\n",
    "\n",
    "After the chain generates a response, it is subsequently stored in the memory, ensuring that the context and information derived from this interaction\n",
    "are preserved for future use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d2b1e4-a395-48bd-a0f3-3a4dfaf2fbee",
   "metadata": {},
   "source": [
    "# Memory types in LangChain : \n",
    "\n",
    "1. Conversation Buffer\n",
    "2. Conversation Window\n",
    "3. Conversation Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948b9c45-a827-4359-bc5f-3783c720b267",
   "metadata": {},
   "source": [
    "# 1. Conversation Buffer\n",
    "\n",
    "A conversation buffer is the most basic and simple type of memory that keeps track of the conversations between the AI and the user. This buffer \n",
    "serves as input or context for generating responses. The model considers the context of the ongoing conversation, making responses more coherent and \n",
    "relevant.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48ed1018-20e3-483b-9dc7-7278eb0b6f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing LangChain modules\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b53cb3b-bcd3-40f5-ab41-1af5f060e362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your key here\n",
    "\n",
    "llm = OpenAI(temperature=0.0,\n",
    "            openai_api_key = \"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70c08c47-4055-4fbd-8a60-601955cbb080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory instantiation and saving context\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "memory.save_context({\"input\": \"Alex is a 9-year old boy.\"}, \n",
    "                    {\"output\": \"Hello Alex! How can I assist you today?\"})\n",
    "memory.save_context({\"input\": \"Alex likes to play football\"}, \n",
    "                    {\"output\": \"That's great to hear! \"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cda9459-5980-4a17-be46-5b96fc603238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a ConversationChain instance with OpenAI\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfac943e-b277-46a5-832d-ea786742a6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Alex is a 9-year old boy.\n",
      "AI: Hello Alex! How can I assist you today?\n",
      "Human: Alex likes to play football\n",
      "AI: That's great to hear! \n",
      "Human: How old is Alex?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " As you mentioned earlier, Alex is 9 years old. Is there anything else you would like to know about Alex?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(conversation.predict(input=\"How old is Alex?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecbc6a1-eeec-4c55-86d8-85ebb9d9c713",
   "metadata": {},
   "source": [
    "# 2. Conversation window\n",
    "\n",
    "Unlike the ConversationBufferMemory, which stores the entire message history, the ConversationBufferWindowMemory keeps a more manageable list of the \n",
    "last k interactions. This approach ensures the most recent k messages are maintained, preventing the buffer from becoming excessively large. Focusing \n",
    "on a limited number of recent messages, the ConversationBufferWindowMemory optimizes resource usage and efficiently captures the context of the\n",
    "ongoing conversation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27ea04dc-74d5-46e3-ae7d-62e864275d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing LangChain modules\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a8bdfa7-c4d7-46b1-923b-1fa5710de05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your key here\n",
    "\n",
    "llm = OpenAI(temperature=0.0,\n",
    "            openai_api_key = \"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df3f9500-c2b3-43a0-ad00-cca5f07373b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory instantiation and saving context\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "memory.save_context({\"input\": \"Alex is a 9-year old boy.\"}, \n",
    "                    {\"output\": \"Hello Alex! How can I assist you today?\"})\n",
    "memory.save_context({\"input\": \"Alex likes to play football\"}, \n",
    "                    {\"output\": \"That's great to hear! \"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91498979-7f74-4763-a51c-1ac1bc2bee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a ConversationChain instance with OpenAI\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e680a346-f405-4e23-ab72-1e93a4725b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Alex likes to play football\n",
      "AI: That's great to hear! \n",
      "Human: How old is Alex?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " I do not have that information, but based on the context of playing football, I would assume Alex is at least old enough to participate in organized sports, so probably around 6 or 7 years old.\n"
     ]
    }
   ],
   "source": [
    "# Since we made k=1 , it only retained the last context , so can't answer properly\n",
    "\n",
    "print(conversation.predict(input=\"How old is Alex?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada5278b-8c5c-4488-aabe-56c649f0f576",
   "metadata": {},
   "source": [
    "# 3. Conversation summary\n",
    "\n",
    "A concise summary of the interaction is often sufficient to store the context. The ConversationSummaryMemory module stores a summary of the \n",
    "interactions over time instead of keeping all or a limited number of past interactions. This method is advantageous for longer conversations, \n",
    "efficiently storing key information over time without overwhelming the model with excessive storage requirements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "566dc103-97d3-4485-9b32-60e691b93ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing LangChain modules\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcd4815a-98b9-4c90-aace-cc5dac43696f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your key here\n",
    "\n",
    "llm = OpenAI(temperature=0.0,\n",
    "            openai_api_key = \"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b43f4bc-7de2-4c0c-affe-429afbc1e99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory instantiation and saving context\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=llm)\n",
    "memory.save_context({\"input\": \"Alex is a 9-year old boy.\"}, \n",
    "                    {\"output\": \"Hello Alex! How can I assist you today?\"})\n",
    "memory.save_context({\"input\": \"Alex likes to play football\"}, \n",
    "                    {\"output\": \"That's great to hear! \"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e391c87-5290-4993-9c32-ce43cf5eacd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a ConversationChain instance with OpenAI\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ddd360d8-373f-46fa-bca3-87752fc12331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The human introduces Alex as a 9-year old boy. The AI greets Alex and asks how it can assist him. The human mentions that Alex likes to play football. The AI responds positively to this information.\n",
      "Human: How old is Alex?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " Alex is 9 years old.\n"
     ]
    }
   ],
   "source": [
    "print(conversation.predict(input=\"How old is Alex?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e79f679-d697-4d1b-aeea-44c2f2f51e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7aba84-874d-44ae-b709-e50d0a4709f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6313fcd4-6043-4fbb-aa39-ece8b01346cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85465ee6-cc77-48bd-9b21-7a41d53028ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c636d8e-af15-4734-9209-6b0d8be7c729",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
